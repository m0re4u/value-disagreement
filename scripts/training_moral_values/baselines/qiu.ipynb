{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import (AutoModelForSequenceClassification, Trainer, TrainingArguments)\n",
    "\n",
    "from aspects.datasets import (ValueEvalDataset, ValueNetDataset)\n",
    "from aspects.datasets.utils import cast_dataset_to_hf, hf_dataset_tokenize\n",
    "from aspects.extraction import ValueConstants, ValueTokenizer\n",
    "\n",
    "\n",
    "def model_init(checkpoint, tokenizer):\n",
    "    \"\"\"\n",
    "    Initialize the model with the checkpoint and tokenizer.\n",
    "    \"\"\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        checkpoint,\n",
    "        num_labels=1,\n",
    "    )\n",
    "    model.resize_token_embeddings(len(tokenizer.tokenizer))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario           [BENEVOLENCE] sleeping with my friend's roomat...\n",
      "orig_label                                                        -1\n",
      "text                sleeping with my friend's roomate, a mutual f...\n",
      "new_class_label                                        benevolence-1\n",
      "value                                                    benevolence\n",
      "Name: 3, dtype: object\n",
      "{'id': 3, 'text': ' Pretty sure im a genetic failure', 'orig_label': -1, 'value': 'stimulation'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.21ba/s]\n",
      "Casting the dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 313.59ba/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  5.98ba/s]\n",
      "Casting the dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 343.17ba/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 12.27ba/s]\n",
      "Casting the dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 357.38ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([  101,  1026, 20858,  1028,   102,  3492,  2469, 10047,  1037,  7403,\n",
      "         4945,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0]), 'labels': tensor(-1.)}\n",
      "Added 10 special value tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "proj_dir = \".\"\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "dataset_net = ValueNetDataset(\n",
    "    f\"{proj_dir}/data/valuenet/\",\n",
    "    return_predefined_splits=True\n",
    ")\n",
    "print(dataset_net[3])\n",
    "\n",
    "train_vn_idx, val_vn_idx, test_vn_idx = dataset_net.get_splits()\n",
    "train_hf = cast_dataset_to_hf(dataset_net[train_vn_idx], \"train\", abs_label=False)\n",
    "val_hf = cast_dataset_to_hf(dataset_net[val_vn_idx], \"val\", abs_label=False)\n",
    "test_hf = cast_dataset_to_hf(dataset_net[test_vn_idx], \"test\", abs_label=False)\n",
    "\n",
    "value_tokenizer = ValueTokenizer(\n",
    "    MODEL_NAME,\n",
    "    input_concat=True,\n",
    "    label_type=\"cast_float\"\n",
    ")\n",
    "\n",
    "print(test_hf[3])\n",
    "\n",
    "# Tokenize data\n",
    "tokenized_dataset_train = hf_dataset_tokenize(train_hf, value_tokenizer, MODEL_NAME, soft_target_type='float')\n",
    "tokenized_dataset_val = hf_dataset_tokenize(val_hf, value_tokenizer, MODEL_NAME, soft_target_type='float')\n",
    "tokenized_dataset_test = hf_dataset_tokenize(test_hf, value_tokenizer, MODEL_NAME, soft_target_type='float')\n",
    "\n",
    "print(tokenized_dataset_test[3])\n",
    "# Add special value tokens and initalize model\n",
    "num_added_tokens = value_tokenizer.tokenizer.add_special_tokens(\n",
    "    {\"additional_special_tokens\": [f\"<{x}>\" for x in ValueConstants.SCHWARTZ_VALUES]})\n",
    "print(f\"Added {num_added_tokens} special value tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_init(MODEL_NAME, value_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "metric = evaluate.load(\"mse\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"qiu_trainer\",\n",
    "    learning_rate=5e-06,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=40,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"wandb\",\n",
    "    metric_for_best_model=\"mse\",\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=20,\n",
    "    load_best_model_at_end=True,\n",
    "    weight_decay=0.00,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = metric.compute(predictions=predictions, references=labels, squared=False)\n",
    "    return rmse\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_dataset_train,\n",
    "    eval_dataset=tokenized_dataset_val,\n",
    "    tokenizer=value_tokenizer.tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(checkpoint, dataset):\n",
    "    model = model_init(checkpoint, value_tokenizer)\n",
    "    args = TrainingArguments(\n",
    "        output_dir=\".\",\n",
    "        do_train=False,\n",
    "        do_eval=False,\n",
    "        do_predict=True,\n",
    "        per_device_eval_batch_size=2\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        tokenizer=value_tokenizer.tokenizer,\n",
    "    )\n",
    "\n",
    "    predictions = trainer.predict(dataset)\n",
    "    pred_int = np.round(predictions.predictions, 0)\n",
    "\n",
    "    f1_simple_rounding = f1_score(y_true=np.abs(predictions.label_ids), y_pred=np.abs(pred_int), average='macro')\n",
    "    print(f\"F1 score simple rounding: {f1_simple_rounding:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file qiu_model/checkpoint-135/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"qiu_model/checkpoint-135/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.13.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30532\n",
      "}\n",
      "\n",
      "loading weights file qiu_model/checkpoint-135/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at qiu_model/checkpoint-135/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, text, value, orig_label.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score simple rounding: 0.546\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(\"qiu_model/checkpoint-135/\", tokenized_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eval = ValueEvalDataset(\n",
    "    f\"{proj_dir}/data/valueeval/dataset-identifying-the-human-values-behind-arguments/\",\n",
    "    cast_to_valuenet=True,\n",
    "    return_predefined_splits=True\n",
    ")\n",
    "test_set_idx = []\n",
    "for i, elem in enumerate(dataset_eval):\n",
    "    if elem['split'] == 'test':\n",
    "        test_set_idx.append(i)\n",
    "\n",
    "test_set = dataset_eval[test_set_idx]\n",
    "test_hf = cast_dataset_to_hf(test_set, \"test\", abs_label=False)\n",
    "\n",
    "value_tokenizer = ValueTokenizer(\n",
    "    MODEL_NAME,\n",
    "    input_concat=True,\n",
    "    label_type=\"cast_float\"\n",
    ")\n",
    "tokenized_dataset_test_eval = hf_dataset_tokenize(test_hf, value_tokenizer, MODEL_NAME, soft_target_type='float')\n",
    "# Add special value tokens and initalize model\n",
    "num_added_tokens = value_tokenizer.tokenizer.add_special_tokens(\n",
    "    {\"additional_special_tokens\": [f\"<{x}>\" for x in ValueConstants.SCHWARTZ_VALUES]})\n",
    "print(f\"Added {num_added_tokens} special value tokens\")\n",
    "\n",
    "evaluate_model(\"qiu_model/checkpoint-135/\", tokenized_dataset_test_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "big_ds = concatenate_datasets([tokenized_dataset_test, tokenized_dataset_test_eval])\n",
    "evaluate_model(\"qiu_model/checkpoint-135/\", big_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
