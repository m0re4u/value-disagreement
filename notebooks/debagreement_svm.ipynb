{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import naive_bayes, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/debagreement.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>body_parent</th>\n",
       "      <th>body_child</th>\n",
       "      <th>submission_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author_parent</th>\n",
       "      <th>exact_time</th>\n",
       "      <th>author_child</th>\n",
       "      <th>datetime</th>\n",
       "      <th>agreement_fraction</th>\n",
       "      <th>individual_kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>gfvmv5x</td>\n",
       "      <td>gfvmzei</td>\n",
       "      <td>kd0se4</td>\n",
       "      <td>So now that they have elected Biden how can we...</td>\n",
       "      <td>They haven't, it is a contested election. The ...</td>\n",
       "      <td>Forensic Audit: \"We conclude that the Dominion...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>guildarts15</td>\n",
       "      <td>1607998349</td>\n",
       "      <td>03-Oct</td>\n",
       "      <td>15/12/2020 02:12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>gyn3we6</td>\n",
       "      <td>gyn4ruu</td>\n",
       "      <td>nfrunb</td>\n",
       "      <td>Tlaib, your family is Hamas. Funded by Iran a ...</td>\n",
       "      <td>She was not truthful when she swore her oath o...</td>\n",
       "      <td>Biden and The Squad's Tlaib stage heated confr...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>oppositeofoutside</td>\n",
       "      <td>1621387168</td>\n",
       "      <td>cmcolfax</td>\n",
       "      <td>19/05/2021 01:19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>gbh1w5x</td>\n",
       "      <td>gbh2dxt</td>\n",
       "      <td>jpv1jr</td>\n",
       "      <td>Most Republicans are happy with Biden as he wi...</td>\n",
       "      <td>I'm not happy about it but I'm not going out a...</td>\n",
       "      <td>President-elect Biden is projected to win Penn...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Rpdaca</td>\n",
       "      <td>1604773521</td>\n",
       "      <td>elang7390</td>\n",
       "      <td>07/11/2020 18:25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>fv8hp2o</td>\n",
       "      <td>fv9lbzd</td>\n",
       "      <td>hbf73b</td>\n",
       "      <td>What is going to happen with this trend is tha...</td>\n",
       "      <td>Shouldn't they only fire use their weapon unle...</td>\n",
       "      <td>Not even an issue of politics it’s wrong this ...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>wiseways9999</td>\n",
       "      <td>1592511116</td>\n",
       "      <td>Hotelier83</td>\n",
       "      <td>18/06/2020 20:11</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>g8ahfgp</td>\n",
       "      <td>g8ahzwk</td>\n",
       "      <td>j8crnu</td>\n",
       "      <td>We gotta start normalizing defending ourselves...</td>\n",
       "      <td>Nah women are about equal rights now a days so...</td>\n",
       "      <td>Young man wearing MAGA hat attacked at school ...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>jwymes44</td>\n",
       "      <td>1602308654</td>\n",
       "      <td>notaglock</td>\n",
       "      <td>10/10/2020 05:44</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label msg_id_parent msg_id_child submission_id  \\\n",
       "0      0       gfvmv5x      gfvmzei        kd0se4   \n",
       "1      2       gyn3we6      gyn4ruu        nfrunb   \n",
       "2      0       gbh1w5x      gbh2dxt        jpv1jr   \n",
       "3      0       fv8hp2o      fv9lbzd        hbf73b   \n",
       "4      0       g8ahfgp      g8ahzwk        j8crnu   \n",
       "\n",
       "                                         body_parent  \\\n",
       "0  So now that they have elected Biden how can we...   \n",
       "1  Tlaib, your family is Hamas. Funded by Iran a ...   \n",
       "2  Most Republicans are happy with Biden as he wi...   \n",
       "3  What is going to happen with this trend is tha...   \n",
       "4  We gotta start normalizing defending ourselves...   \n",
       "\n",
       "                                          body_child  \\\n",
       "0  They haven't, it is a contested election. The ...   \n",
       "1  She was not truthful when she swore her oath o...   \n",
       "2  I'm not happy about it but I'm not going out a...   \n",
       "3  Shouldn't they only fire use their weapon unle...   \n",
       "4  Nah women are about equal rights now a days so...   \n",
       "\n",
       "                                     submission_text   subreddit  \\\n",
       "0  Forensic Audit: \"We conclude that the Dominion...  Republican   \n",
       "1  Biden and The Squad's Tlaib stage heated confr...  Republican   \n",
       "2  President-elect Biden is projected to win Penn...  Republican   \n",
       "3  Not even an issue of politics it’s wrong this ...  Republican   \n",
       "4  Young man wearing MAGA hat attacked at school ...  Republican   \n",
       "\n",
       "       author_parent  exact_time author_child          datetime  \\\n",
       "0        guildarts15  1607998349       03-Oct  15/12/2020 02:12   \n",
       "1  oppositeofoutside  1621387168     cmcolfax  19/05/2021 01:19   \n",
       "2             Rpdaca  1604773521    elang7390  07/11/2020 18:25   \n",
       "3       wiseways9999  1592511116   Hotelier83  18/06/2020 20:11   \n",
       "4           jwymes44  1602308654    notaglock  10/10/2020 05:44   \n",
       "\n",
       "   agreement_fraction  individual_kappa  \n",
       "0            1.000000          1.000000  \n",
       "1            1.000000          1.000000  \n",
       "2            1.000000          1.000000  \n",
       "3            0.666667          0.333333  \n",
       "4            1.000000          1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_splits(df_group, train_len_pct=0.80, val_len_pct=0.10):\n",
    "    total_length = len(df_group)\n",
    "    train_length = int(train_len_pct * total_length)\n",
    "    val_length = int(val_len_pct * total_length)\n",
    "    test_length = total_length - (train_length + val_length)\n",
    "    train_set = df_group.iloc[:train_length]\n",
    "    val_set = df_group.iloc[train_length:train_length + val_length]\n",
    "    test_set = df_group.iloc[train_length + val_length:]\n",
    "    assert len(train_set) == train_length\n",
    "    assert len(val_set) == val_length\n",
    "    assert len(test_set) == test_length\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "trains = []\n",
    "vals = []\n",
    "tests = []\n",
    "for gname, g in df.groupby(\"subreddit\"):\n",
    "    g[\"date_py\"] = pd.to_datetime(df[\"datetime\"])\n",
    "    g = g.sort_values(by=\"date_py\")\n",
    "    train, val, test = get_splits(g)\n",
    "    trains.append(train)\n",
    "    vals.append(val)\n",
    "    tests.append(test)\n",
    "\n",
    "df_train = pd.concat(trains)\n",
    "df_val = pd.concat(vals)\n",
    "df_test = pd.concat(tests)\n",
    "\n",
    "print(len(df_train))\n",
    "print(len(df_val))\n",
    "print(len(df_test))\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(row):\n",
    "    classification_string = row.body_parent + \"</s>\" + row.body_child\n",
    "    inputs = classification_string.lower()\n",
    "    inputs = word_tokenize(inputs)\n",
    "    tag_map = defaultdict(lambda : wn.NOUN)\n",
    "    tag_map['J'] = wn.ADJ\n",
    "    tag_map['V'] = wn.VERB\n",
    "    tag_map['R'] = wn.ADV\n",
    "    final_inputs = []\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    for word, tag in pos_tag(inputs):\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word, tag_map[tag[0]])\n",
    "            final_inputs.append(word_Final)\n",
    "    return final_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes around 7 min\n",
    "small_train = df_train\n",
    "small_test = df_val\n",
    "X_train = list(small_train[['body_parent', 'body_child']].apply(tokenize, axis=1, result_type='reduce'))\n",
    "Y_train = list(small_train['label'])\n",
    "X_test = list(small_test[['body_parent', 'body_child']].apply(tokenize, axis=1, result_type='reduce'))\n",
    "Y_test = list(small_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "train_corpus = [\" \".join(x) for x in X_train]\n",
    "X_train_tfidf = vectorizer.fit_transform(train_corpus)\n",
    "test_corpus = [\" \".join(x) for x in X_test]\n",
    "X_test_tfidf = vectorizer.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Took around 15 min\n",
    "\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "svm_model = svm.SVC()\n",
    "Naive.fit(X_train_tfidf,Y_train)\n",
    "svm_model.fit(X_train_tfidf,Y_train)\n",
    "predictions_NB = Naive.predict(X_test_tfidf)\n",
    "predictions_SVM = svm_model.predict(X_test_tfidf)\n",
    "print(\"Naive Bayes Accuracy Score -> \",classification_report(Y_test, predictions_NB))\n",
    "print(\"SVM Accuracy Score -> \", classification_report(Y_test, predictions_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train_tfidf, Y_train)\n",
    "predictions_tree = clf.predict(X_test_tfidf)\n",
    "print(\"Tree Accuracy Score -> \", classification_report(Y_test, predictions_tree))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
